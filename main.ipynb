{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install scikit-image>=0.18.0\n",
    "!pip install scikit-learn>=1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-28T10:52:31.567433Z",
     "iopub.status.busy": "2025-05-28T10:52:31.567125Z",
     "iopub.status.idle": "2025-05-28T10:52:49.407282Z",
     "shell.execute_reply": "2025-05-28T10:52:49.406391Z",
     "shell.execute_reply.started": "2025-05-28T10:52:31.567403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 10:52:34.056921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748429554.307919      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748429554.380265      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.layers import LeakyReLU, GlobalAveragePooling2D\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(f\"GPU Available: True. Devices: {gpu_devices}\")\n",
    "else:\n",
    "    print(\"GPU Available: False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters - improved from reference solutions\n",
    "class Config:\n",
    "    # Multi-scale approach from rank 1 and rank 4 solutions\n",
    "    SCALES = [0.4, 0.5]  # Multiple scales for robustness, reduced for demo\n",
    "    PATCH_SIZE = 224  # Adjusted for common VGG16 input, rank 2 suggested larger\n",
    "    BATCH_SIZE = 16  # Adjusted for memory constraints\n",
    "    EPOCHS = 2  # Reduced significantly for quick demonstration\n",
    "    LEARNING_RATE = 1e-4\n",
    "\n",
    "    # Class names for better organization\n",
    "    CLASS_NAMES = ['adult_males', 'subadult_males',\n",
    "                   'adult_females', 'juveniles', 'pups']\n",
    "    N_CLASSES = 5\n",
    "\n",
    "    # Data paths - adjust if your data is located elsewhere\n",
    "    DATA_ROOT_KAGGLE = \"/kaggle/input/noaa-fisheries-steller-sea-lion-population-count/KaggleNOAASeaLions\"\n",
    "    # Assuming a local 'data' folder with Train, TrainDotted, Mismatched...\n",
    "    DATA_ROOT_LOCAL = \"data\"\n",
    "\n",
    "    if os.path.exists(DATA_ROOT_KAGGLE):\n",
    "        DATA_ROOT = DATA_ROOT_KAGGLE\n",
    "    elif os.path.exists(DATA_ROOT_LOCAL):\n",
    "        DATA_ROOT = DATA_ROOT_LOCAL\n",
    "    else:\n",
    "        # Fallback if no data directory is found, notebook will use dummy data\n",
    "        print(\"Warning: Data directories not found. Will use dummy data.\")\n",
    "        DATA_ROOT = \"data_not_found\"\n",
    "        # Create dummy directories if they don't exist to prevent later errors\n",
    "        os.makedirs(os.path.join(DATA_ROOT, \"Train\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(DATA_ROOT, \"TrainDotted\"), exist_ok=True)\n",
    "        # Create an empty mismatch file\n",
    "        with open(os.path.join(DATA_ROOT, \"MismatchedTrainImages.txt\"), 'w') as f:\n",
    "            pass\n",
    "\n",
    "    TRAIN_DIR = os.path.join(DATA_ROOT, \"Train\")\n",
    "    TRAIN_DOTTED_DIR = os.path.join(DATA_ROOT, \"TrainDotted\")\n",
    "    MISMATCH_FILE = os.path.join(DATA_ROOT, \"MismatchedTrainImages.txt\")\n",
    "    TEST_DIR = os.path.join(DATA_ROOT, \"Test\")  # For submission generation\n",
    "\n",
    "\n",
    "config = Config()\n",
    "print(f\"Configuration loaded. Data root set to: {config.DATA_ROOT}\")\n",
    "print(\n",
    "    f\"Using scales: {config.SCALES}, Patch size: {config.PATCH_SIZE}, Epochs: {config.EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:53:11.159672Z",
     "iopub.status.busy": "2025-05-28T10:53:11.159358Z",
     "iopub.status.idle": "2025-05-28T10:53:11.171998Z",
     "shell.execute_reply": "2025-05-28T10:53:11.171059Z",
     "shell.execute_reply.started": "2025-05-28T10:53:11.159650Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def enhanced_get_data(filename, scale=0.4, patch_size=224):\n",
    "    try:\n",
    "        image_dotted_path = os.path.join(config.TRAIN_DOTTED_DIR, filename)\n",
    "        image_original_path = os.path.join(config.TRAIN_DIR, filename)\n",
    "\n",
    "        if not os.path.exists(image_dotted_path) or not os.path.exists(image_original_path):\n",
    "            # print(f\"Warning: Image files for {filename} not found.\")\n",
    "            return None, None\n",
    "\n",
    "        image_dotted = cv2.imread(image_dotted_path)\n",
    "        image_original = cv2.imread(image_original_path)\n",
    "\n",
    "        if image_dotted is None or image_original is None:\n",
    "            # print(f\"Warning: Could not load image {filename}. Skipping.\")\n",
    "            return None, None\n",
    "\n",
    "        img_blurred = cv2.GaussianBlur(image_dotted, (5, 5), 0)\n",
    "        diff = cv2.absdiff(image_dotted, image_original)\n",
    "        mask_gray = cv2.cvtColor(image_dotted, cv2.COLOR_BGR2GRAY)\n",
    "        mask_bin = np.zeros_like(mask_gray)\n",
    "        # Increased threshold for dot mask from 50 to 20 to catch more faint dots\n",
    "        mask_bin[mask_gray > 20] = 255\n",
    "        masked_diff = cv2.bitwise_or(diff, diff, mask=mask_bin)\n",
    "        gray_diff = np.max(masked_diff, axis=2)\n",
    "\n",
    "        blobs = skimage.feature.blob_log(\n",
    "            gray_diff, min_sigma=2, max_sigma=7, num_sigma=3, threshold=0.01  # Adjusted blob params\n",
    "        )\n",
    "\n",
    "        h, w, _ = image_original.shape\n",
    "        grid_w_count = int(np.ceil((w * scale) / patch_size))\n",
    "        grid_h_count = int(np.ceil((h * scale) / patch_size))\n",
    "        result_grid = np.zeros(\n",
    "            (grid_h_count, grid_w_count, config.N_CLASSES), dtype='float32')\n",
    "\n",
    "        for blob in blobs:\n",
    "            y, x, sigma = map(int, blob)\n",
    "            if 0 <= y < h and 0 <= x < w:\n",
    "                b_val, g_val, r_val = img_blurred[y, x]\n",
    "                grid_x_idx = min(\n",
    "                    int((x * scale) // patch_size), grid_w_count - 1)\n",
    "                grid_y_idx = min(\n",
    "                    int((y * scale) // patch_size), grid_h_count - 1)\n",
    "\n",
    "                cl = -1\n",
    "                if r_val > 200 and g_val < 50 and b_val < 50:\n",
    "                    cl = 0  # Adult Males (Red)\n",
    "                elif r_val > 200 and g_val < 50 and b_val > 200:\n",
    "                    cl = 1  # Subadult Males (Magenta)\n",
    "                elif r_val < 50 and g_val > 150 and b_val < 50:\n",
    "                    cl = 2  # Adult Females (Green)\n",
    "                elif r_val < 50 and g_val < 50 and b_val > 150:\n",
    "                    cl = 3  # Juveniles (Blue)\n",
    "                elif r_val > 60 and r_val < 120 and g_val < 75 and b_val < 50:\n",
    "                    cl = 4  # Pups (Brown)\n",
    "\n",
    "                if cl != -1:\n",
    "                    result_grid[grid_y_idx, grid_x_idx, cl] += 1\n",
    "\n",
    "        valid_region_mask = (np.sum(image_dotted, axis=2) > 10).astype(\n",
    "            'uint8')  # Mask out very dark regions\n",
    "        valid_region_mask_bgr = cv2.cvtColor(\n",
    "            valid_region_mask * 255, cv2.COLOR_GRAY2BGR)\n",
    "        processed_img_masked = image_original * \\\n",
    "            (valid_region_mask_bgr // 255)  # Apply mask\n",
    "\n",
    "        processed_img_resized = cv2.resize(\n",
    "            processed_img_masked, (int(w * scale), int(h * scale)))\n",
    "        processed_img_normalized = processed_img_resized.astype(\n",
    "            'float32') / 255.0\n",
    "\n",
    "        h_new, w_new, _ = processed_img_normalized.shape\n",
    "        patches_x, patches_y = [], []\n",
    "\n",
    "        for r_idx in range(grid_h_count):\n",
    "            for c_idx in range(grid_w_count):\n",
    "                y_start, y_end = r_idx * patch_size, (r_idx + 1) * patch_size\n",
    "                x_start, x_end = c_idx * patch_size, (c_idx + 1) * patch_size\n",
    "\n",
    "                # Ensure patch boundaries are within the scaled image dimensions\n",
    "                y_end = min(y_end, h_new)\n",
    "                x_end = min(x_end, w_new)\n",
    "\n",
    "                # Check if the actual patch start is still valid (e.g. for last row/col)\n",
    "                if y_start >= h_new or x_start >= w_new:\n",
    "                    continue\n",
    "\n",
    "                patch = processed_img_normalized[y_start:y_end,\n",
    "                                                 x_start:x_end, :]\n",
    "                actual_h, actual_w, _ = patch.shape\n",
    "\n",
    "                # Pad if patch is smaller than target size (edges)\n",
    "                if actual_h < patch_size or actual_w < patch_size:\n",
    "                    pad_h = patch_size - actual_h\n",
    "                    pad_w = patch_size - actual_w\n",
    "                    # Pad with zeros (black)\n",
    "                    patch = np.pad(patch, ((0, pad_h), (0, pad_w),\n",
    "                                   (0, 0)), mode='constant', constant_values=0)\n",
    "\n",
    "                # Ensure final shape is correct\n",
    "                if patch.shape == (patch_size, patch_size, 3):\n",
    "                    patches_x.append(patch)\n",
    "                    patches_y.append(result_grid[r_idx, c_idx, :])\n",
    "\n",
    "        if not patches_x:  # If no patches were created for this image\n",
    "            return None, None\n",
    "\n",
    "        return np.array(patches_x), np.array(patches_y)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename} at scale {scale}: {e}\")\n",
    "        import traceback\n",
    "        # traceback.print_exc() # Uncomment for detailed error stack\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "\n",
    "def custom_rmse_loss(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(tf.cast(y_true, tf.float32) - y_pred)))\n",
    "\n",
    "\n",
    "print(\"Data processing functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:54:13.102249Z",
     "iopub.status.busy": "2025-05-28T10:54:13.101940Z",
     "iopub.status.idle": "2025-05-28T10:54:13.110363Z",
     "shell.execute_reply": "2025-05-28T10:54:13.109606Z",
     "shell.execute_reply.started": "2025-05-28T10:54:13.102228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_enhanced_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), padding='same',\n",
    "               input_shape=input_shape), BatchNormalization(), Activation('relu'),\n",
    "        Conv2D(32, (3, 3), padding='same'), BatchNormalization(), Activation(\n",
    "            'relu'), MaxPooling2D((2, 2)), Dropout(0.2),\n",
    "        Conv2D(64, (3, 3), padding='same'), BatchNormalization(), Activation('relu'),\n",
    "        Conv2D(64, (3, 3), padding='same'), BatchNormalization(), Activation(\n",
    "            'relu'), MaxPooling2D((2, 2)), Dropout(0.3),\n",
    "        Conv2D(128, (3, 3), padding='same'), BatchNormalization(\n",
    "        ), Activation('relu'),\n",
    "        Conv2D(128, (3, 3), padding='same'), BatchNormalization(\n",
    "        ), Activation('relu'), MaxPooling2D((2, 2)), Dropout(0.4),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'), Dropout(0.5),\n",
    "        # Linear activation for regression\n",
    "        Dense(config.N_CLASSES, activation='linear')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_vgg_transfer_model(input_shape):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False,\n",
    "                       input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze base layers initially\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(config.N_CLASSES, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_data_generator():\n",
    "    return ImageDataGenerator(\n",
    "        rotation_range=45,  # Increased rotation\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        width_shift_range=0.15,  # Increased shift\n",
    "        height_shift_range=0.15,\n",
    "        zoom_range=0.2,  # Increased zoom\n",
    "        brightness_range=[0.7, 1.3],  # Wider brightness range\n",
    "        fill_mode='nearest')\n",
    "\n",
    "\n",
    "print(\"Model architectures and data generator defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:56:38.738838Z",
     "iopub.status.busy": "2025-05-28T10:56:38.738516Z",
     "iopub.status.idle": "2025-05-28T10:56:38.762260Z",
     "shell.execute_reply": "2025-05-28T10:56:38.761400Z",
     "shell.execute_reply.started": "2025-05-28T10:56:38.738806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_training_data(max_files=2, scales=None):  # Reduced max_files for demo\n",
    "    if scales is None:\n",
    "        scales = config.SCALES\n",
    "\n",
    "    bad_files = set()\n",
    "    if os.path.exists(config.MISMATCH_FILE):\n",
    "        try:\n",
    "            with open(config.MISMATCH_FILE, 'r') as f:\n",
    "                bad_files = set(line.strip() for line in f if line.strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read mismatch file: {e}\")\n",
    "\n",
    "    all_image_files = []\n",
    "    if os.path.exists(config.TRAIN_DIR):\n",
    "        all_image_files = [f for f in os.listdir(config.TRAIN_DIR)\n",
    "                           if f.endswith('.jpg') and f not in bad_files]\n",
    "        # Shuffle for variety if max_files is small\n",
    "        random.shuffle(all_image_files)\n",
    "\n",
    "    if not all_image_files:\n",
    "        print(\"No training image files found. Using dummy data.\")\n",
    "        # Create dummy data if no real data is found\n",
    "        dummy_X = np.random.rand(\n",
    "            32, config.PATCH_SIZE, config.PATCH_SIZE, 3).astype('float32')\n",
    "        dummy_y = np.random.randint(\n",
    "            0, 2, (32, config.N_CLASSES)).astype('float32')\n",
    "        return dummy_X, dummy_y\n",
    "\n",
    "    files_to_process = all_image_files[:\n",
    "                                       max_files] if max_files else all_image_files\n",
    "    print(f\"Loading data from {len(files_to_process)} files, scales: {scales}\")\n",
    "\n",
    "    X_all, y_all = [], []\n",
    "    for scale_val in tqdm.tqdm(scales, desc=\"Processing Scales\"):\n",
    "        for filename in tqdm.tqdm(files_to_process, desc=f\"Scale {scale_val} Files\", leave=False):\n",
    "            X_batch, y_batch = enhanced_get_data(\n",
    "                filename, scale=scale_val, patch_size=config.PATCH_SIZE)\n",
    "            if X_batch is not None and len(X_batch) > 0:\n",
    "                X_all.extend(X_batch)\n",
    "                y_all.extend(y_batch)\n",
    "\n",
    "    if not X_all:\n",
    "        print(\"No patches extracted from available files. Using dummy data.\")\n",
    "        dummy_X = np.random.rand(\n",
    "            32, config.PATCH_SIZE, config.PATCH_SIZE, 3).astype('float32')\n",
    "        dummy_y = np.random.randint(\n",
    "            0, 2, (32, config.N_CLASSES)).astype('float32')\n",
    "        return dummy_X, dummy_y\n",
    "\n",
    "    X = np.array(X_all)\n",
    "    y = np.array(y_all)\n",
    "\n",
    "    print(f\"Data loading complete. Total patches: {len(X)}\")\n",
    "    if len(X) > 0:\n",
    "        print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "        print(f\"y distribution (sum per class): {np.sum(y, axis=0)}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "print(\"Training data loading function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:57:03.212025Z",
     "iopub.status.busy": "2025-05-28T10:57:03.211712Z",
     "iopub.status.idle": "2025-05-28T10:57:03.216941Z",
     "shell.execute_reply": "2025-05-28T10:57:03.215980Z",
     "shell.execute_reply.started": "2025-05-28T10:57:03.212001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948\n"
     ]
    }
   ],
   "source": [
    "def train_model_wrapper(model, X_train, y_train, X_val, y_val, model_name=\"model\"):\n",
    "    # Ensure model is compiled before training\n",
    "    if not model._is_compiled:\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=config.LEARNING_RATE),\n",
    "            loss=custom_rmse_loss,\n",
    "            metrics=['mse', 'mae']\n",
    "        )\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5,\n",
    "                      restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                          patience=3, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(f\"{model_name}_best.keras\",\n",
    "                        monitor='val_loss', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nTraining {model_name}... Input shape: {X_train.shape}\")\n",
    "    # model.summary() # Can be verbose\n",
    "\n",
    "    datagen = create_data_generator()\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=config.BATCH_SIZE),\n",
    "        steps_per_epoch=max(1, len(X_train) // config.BATCH_SIZE),\n",
    "        epochs=config.EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    # Load best weights saved by ModelCheckpoint\n",
    "    if os.path.exists(f\"{model_name}_best.keras\"):\n",
    "        model.load_weights(f\"{model_name}_best.keras\")\n",
    "        print(f\"Loaded best weights for {model_name} from checkpoint.\")\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def evaluate_model_performance(model, X_test, y_test, model_name=\"model\"):\n",
    "    y_pred_raw = model.predict(X_test, verbose=0)\n",
    "    # Post-processing: Clip negative predictions and apply threshold (from Rank 1)\n",
    "    # Ensure non-negative counts\n",
    "    y_pred_processed = np.clip(y_pred_raw, 0, None)\n",
    "    y_pred_thresholded = y_pred_processed * \\\n",
    "        (y_pred_processed > 0.3)  # Thresholding idea\n",
    "\n",
    "    rmse_raw = rmse(y_test, y_pred_raw)\n",
    "    rmse_processed = rmse(y_test, y_pred_processed)\n",
    "    rmse_thresholded = rmse(y_test, y_pred_thresholded)\n",
    "\n",
    "    print(f\"\\n--- {model_name} Evaluation Results ---\")\n",
    "    print(f\"RMSE (Raw Predictions): {rmse_raw:.4f}\")\n",
    "    print(f\"RMSE (Processed - Clipped): {rmse_processed:.4f}\")\n",
    "    print(\n",
    "        f\"RMSE (Processed - Clipped & Thresholded > 0.3): {rmse_thresholded:.4f}\")\n",
    "\n",
    "    true_counts = np.sum(y_test, axis=0)\n",
    "    # Using rounded thresholded for final count comparison\n",
    "    pred_counts_final = np.sum(np.round(y_pred_thresholded), axis=0)\n",
    "\n",
    "    print(\"Class-wise Counts (True vs Predicted [Rounded Thresholded]):\")\n",
    "    for i, name in enumerate(config.CLASS_NAMES):\n",
    "        print(\n",
    "            f\"{name:>15s}: True={true_counts[i]:<5.0f} Pred={pred_counts_final[i]:<5.0f} Diff={(pred_counts_final[i]-true_counts[i]):<5.0f}\")\n",
    "    return {'rmse': rmse_processed, 'rmse_thresholded': rmse_thresholded, 'predictions': y_pred_processed}\n",
    "\n",
    "\n",
    "def plot_training_summary(history, model_name):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'{model_name} - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if 'mae' in history.history:\n",
    "        plt.plot(history.history['mae'], label='Train MAE')\n",
    "        plt.plot(history.history['val_mae'], label='Val MAE')\n",
    "        plt.title(f'{model_name} - MAE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Model training and evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:57:40.312466Z",
     "iopub.status.busy": "2025-05-28T10:57:40.312135Z",
     "iopub.status.idle": "2025-05-28T10:57:40.318165Z",
     "shell.execute_reply": "2025-05-28T10:57:40.317325Z",
     "shell.execute_reply.started": "2025-05-28T10:57:40.312443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_main_pipeline():\n",
    "    print(\"=== Starting Sea Lion Counting Pipeline ===\")\n",
    "\n",
    "    # 1. Load Data\n",
    "    print(\"\\n--- Step 1: Loading Training Data ---\")\n",
    "    # For demonstration, using very few files and only one scale initially\n",
    "    X, y = load_training_data(max_files=config.EPOCHS,\n",
    "                              scales=config.SCALES[:1])\n",
    "\n",
    "    if X is None or len(X) == 0:\n",
    "        print(\"Critical error: No training data loaded. Exiting pipeline.\")\n",
    "        return {}, {}, None, None  # Return empty dicts and None for data\n",
    "\n",
    "    if len(X) < config.BATCH_SIZE * 2:  # Ensure enough data for train/val/test split and batching\n",
    "        print(\n",
    "            f\"Warning: Very few samples ({len(X)}). Results may not be meaningful. Duplicating data for stability.\")\n",
    "        factor = (config.BATCH_SIZE * 2) // len(X) + 1\n",
    "        X = np.concatenate([X] * factor, axis=0)\n",
    "        y = np.concatenate([y] * factor, axis=0)\n",
    "        print(f\"Augmented sample count to {len(X)}\")\n",
    "\n",
    "    # 2. Split Data\n",
    "    print(\"\\n--- Step 2: Splitting Data ---\")\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        # 0.25 * 0.8 = 0.2 for val\n",
    "        X_train_full, y_train_full, test_size=0.25, random_state=42)\n",
    "    print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "    trained_models = {}\n",
    "    evaluation_results = {}\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    # 3. Train Enhanced CNN\n",
    "    print(\"\\n--- Step 3: Training Enhanced CNN ---\")\n",
    "    try:\n",
    "        cnn_model_instance = create_enhanced_cnn(input_shape)\n",
    "        cnn_model_instance, cnn_history = train_model_wrapper(\n",
    "            cnn_model_instance, X_train, y_train, X_val, y_val, \"Enhanced_CNN\")\n",
    "        trained_models[\"Enhanced_CNN\"] = cnn_model_instance\n",
    "        evaluation_results[\"Enhanced_CNN\"] = evaluate_model_performance(\n",
    "            cnn_model_instance, X_test, y_test, \"Enhanced_CNN\")\n",
    "        plot_training_summary(cnn_history, \"Enhanced_CNN\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error training Enhanced CNN: {e}\")\n",
    "        # traceback.print_exc()\n",
    "\n",
    "    # 4. Train VGG16 Transfer Model\n",
    "    print(\"\\n--- Step 4: Training VGG16 Transfer Model ---\")\n",
    "    try:\n",
    "        vgg_model_instance = create_vgg_transfer_model(input_shape)\n",
    "        vgg_model_instance, vgg_history = train_model_wrapper(\n",
    "            vgg_model_instance, X_train, y_train, X_val, y_val, \"VGG16_Transfer\")\n",
    "        trained_models[\"VGG16_Transfer\"] = vgg_model_instance\n",
    "        evaluation_results[\"VGG16_Transfer\"] = evaluate_model_performance(\n",
    "            vgg_model_instance, X_test, y_test, \"VGG16_Transfer\")\n",
    "        plot_training_summary(vgg_history, \"VGG16_Transfer\")\n",
    "\n",
    "        # Optional: Fine-tune VGG16 (if epochs are sufficient)\n",
    "        if config.EPOCHS > 5:  # Only fine-tune if initial training was somewhat substantial\n",
    "            print(\"\\n--- Step 4b: Fine-tuning VGG16 Transfer Model ---\")\n",
    "            # Unfreeze some layers of VGG16\n",
    "            for layer in vgg_model_instance.layers[-4:]:\n",
    "                # Keep BN frozen as per best practices\n",
    "                if not isinstance(layer, BatchNormalization):\n",
    "                    layer.trainable = True\n",
    "            vgg_model_instance.compile(\n",
    "                # Lower LR for fine-tuning\n",
    "                optimizer=Adam(learning_rate=config.LEARNING_RATE / 10),\n",
    "                loss=custom_rmse_loss, metrics=['mse', 'mae']\n",
    "            )\n",
    "            vgg_model_instance, vgg_ft_history = train_model_wrapper(\n",
    "                vgg_model_instance, X_train, y_train, X_val, y_val, \"VGG16_FineTuned\")\n",
    "            # Overwrite or add as new\n",
    "            trained_models[\"VGG16_FineTuned\"] = vgg_model_instance\n",
    "            evaluation_results[\"VGG16_FineTuned\"] = evaluate_model_performance(\n",
    "                vgg_model_instance, X_test, y_test, \"VGG16_FineTuned\")\n",
    "            plot_training_summary(vgg_ft_history, \"VGG16_FineTuned\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error training VGG16 model: {e}\")\n",
    "        # traceback.print_exc()\n",
    "\n",
    "    # 5. Ensemble Predictions (if multiple models trained successfully)\n",
    "    if len(trained_models) > 1:\n",
    "        print(\"\\n--- Step 5: Creating Ensemble Predictions ---\")\n",
    "        ensemble_preds_list = []\n",
    "        for model_name, model_instance in trained_models.items():\n",
    "            # Use the processed predictions from evaluation_results if available\n",
    "            if model_name in evaluation_results and 'predictions' in evaluation_results[model_name]:\n",
    "                ensemble_preds_list.append(\n",
    "                    evaluation_results[model_name]['predictions'])\n",
    "            else:  # Fallback to predict again if needed\n",
    "                pred = model_instance.predict(X_test, verbose=0)\n",
    "                pred_clipped = np.clip(pred, 0, None)\n",
    "                ensemble_preds_list.append(pred_clipped)\n",
    "\n",
    "        if ensemble_preds_list:\n",
    "            # Averaging ensemble\n",
    "            avg_ensemble_pred = np.mean(ensemble_preds_list, axis=0)\n",
    "            avg_ensemble_pred_thresholded = avg_ensemble_pred * \\\n",
    "                (avg_ensemble_pred > 0.3)\n",
    "\n",
    "            ensemble_rmse_val = rmse(y_test, avg_ensemble_pred)\n",
    "            ensemble_rmse_thresh_val = rmse(\n",
    "                y_test, avg_ensemble_pred_thresholded)\n",
    "\n",
    "            print(\n",
    "                f\"Ensemble (Average) RMSE (Processed): {ensemble_rmse_val:.4f}\")\n",
    "            print(\n",
    "                f\"Ensemble (Average) RMSE (Processed & Thresholded): {ensemble_rmse_thresh_val:.4f}\")\n",
    "            evaluation_results[\"Ensemble_Average\"] = {\n",
    "                'rmse': ensemble_rmse_val, 'rmse_thresholded': ensemble_rmse_thresh_val, 'predictions': avg_ensemble_pred}\n",
    "\n",
    "    # 6. Final Summary\n",
    "    print(\"\\n=== Pipeline Execution Summary ===\")\n",
    "    if not evaluation_results:\n",
    "        print(\"No models were successfully trained or evaluated.\")\n",
    "    else:\n",
    "        for name, res in evaluation_results.items():\n",
    "            print(f\"{name:>20s}: RMSE (Processed) = {res.get('rmse', float('nan')):.4f}, RMSE (Thresholded) = {res.get('rmse_thresholded', float('nan')):.4f}\")\n",
    "\n",
    "        best_model_name = min(evaluation_results.items(), key=lambda x: x[1].get(\n",
    "            'rmse_thresholded', float('inf')))[0]\n",
    "        print(\n",
    "            f\"\\nBest performing model (based on thresholded RMSE): {best_model_name}\")\n",
    "\n",
    "    return trained_models, evaluation_results, X_test, y_test\n",
    "\n",
    "\n",
    "print(\"Main training pipeline function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:57:54.368944Z",
     "iopub.status.busy": "2025-05-28T10:57:54.368642Z",
     "iopub.status.idle": "2025-05-28T10:57:54.373380Z",
     "shell.execute_reply": "2025-05-28T10:57:54.372530Z",
     "shell.execute_reply.started": "2025-05-28T10:57:54.368924Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "# This is the main execution block for the notebook.\n",
    "print(\"Starting the improved sea lion counting pipeline execution...\")\n",
    "print(f\"Using {config.EPOCHS} epochs for training. This is a demo run.\")\n",
    "\n",
    "trained_models_dict = {}\n",
    "eval_results_dict = {}\n",
    "X_test_final, y_test_final = None, None\n",
    "\n",
    "try:\n",
    "    trained_models_dict, eval_results_dict, X_test_final, y_test_final = run_main_pipeline()\n",
    "\n",
    "    print(\"\\n=== FINAL EXECUTION STATUS ===\")\n",
    "    if trained_models_dict:\n",
    "        print(\n",
    "            f\"Successfully trained {len(trained_models_dict)} model(s): {list(trained_models_dict.keys())}\")\n",
    "        # Save the best model (if any was deemed best)\n",
    "        if eval_results_dict:\n",
    "            best_model_key = min(eval_results_dict, key=lambda k: eval_results_dict[k].get(\n",
    "                'rmse_thresholded', float('inf')))\n",
    "            if best_model_key in trained_models_dict:\n",
    "                trained_models_dict[best_model_key].save(\n",
    "                    f\"best_overall_model.keras\")\n",
    "                print(\n",
    "                    f\"Saved best model ({best_model_key}) as best_overall_model.keras\")\n",
    "    else:\n",
    "        print(\"No models were trained successfully in this run.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An critical error occurred during pipeline execution: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    print(\"Pipeline execution finished.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7422204,
     "sourceId": 11816852,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7531683,
     "sourceId": 11976472,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7532202,
     "sourceId": 11977239,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
